# Evaluate-Regression-and-Regularized-Regression-Models-in-a-Real-World-Application
Regression is fundamental to predictive modeling, but Ordinary Least Squares (OLS) often underperforms in high-dimensional settings due to multicollinearity, overfitting, and unstable coefficients. Regularization techniques which include Ridge, Lasso, and Elastic Net do address these challenges by introducing penalty terms that shrink coefficients, resulting in more stable estimates, improved out-of-sample performance, and enhanced interpretability. The research in this project applies these regularized regression methods to the NutritionData.csv dataset, obtained from online sources.

Exploratory data analysis is carried out to visualize the shape, top 5 records, bottom 5 records, data types and a summarization of statistics. The data set has a lot of incomplete records and has mixed data types that require a lot of data preprocessing, imputing the missing numerical and categorical data and removing outliers. Linear regression and tree models are then implemented after preprocessing to predict the number of calories in the nutrition features. Six models ( linear and ensemble models) are built to evaluate regression: Ordinary Least Squares (OLS), Ridge , Lasso, Elastic Net, Random forest (RF) and XGBoost. Model performance is evaluated using k-fold cross validation using a minimum of k= 5. The metrics used to evaluate the models are Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), Coefficient of Determination (R2) and Adjusted R2. Hyperparameter tuning  using Grid Search for linear models and Random search for tree models is then implemented using cross validation Selected hyperparameters are reported and justified. The empirical findings are contextualized within a critical review of recent literature on regularization and the bias–variance tradeoff.

Problem Statement

A hypothetical scenario exists in which the Murage Mills advertising team has the nutrition information of some test foods that they plan to bring to market soon. However, their scientists have not had a chance to test each nutrition products’ amount of calories as of yet. The management, therefore, require the data scientist to build a model that can estimate the number of calories in a food type based on the nutritional information in the data set. This will enable the company’s marketing department to get a head start on their marketing material rather than having to wait for the research scientists testing which is estimated to take three months to perform The questions being answered are twofold, first, do linear methods of  regression ( OLS, Ridge, Lasso, or Elastic Net) outperform ensemble methods (RF and XGBoost)? Secondly, which linear regression model (OLS, Ridge, Lasso, or Elastic Net ) performs most accurately in predicting the amount of calories when faced with high dimensionality and a lot of missing numbers the data set?

Conclusion and Reflections

This research successfully demonstrates that while advanced regularized linear models remain robust and interpretable tools, modern ensemble methods like XGBOOST deliver superior predictive power for complex nutritional prediction tasks, provided they are carefully regularized to manage overfitting. The project underscores a key machine learning principle; that there does not exist a universally best model; the optimal choice is dictated by the data structure and the business problem context, therefore, emphasizing the need for systematic preprocessing, model comparison, and hyperparameter optimization as is accomplished in this study.The results of this study are ready for marketing to be used at Murage Mills for marketing while waiting to conduct scientific research Business context justification shows that the choice of XGBOOST as the best model is well-justified for the stated problem of calorie prediction. A prediction error (RMSE) of approximately16 calories on a calorie scale that often ranges into the hundreds is likely accurate enough for marketing purposes. The slight sacrifice in interpretability for a significant gain in accuracy is a valid trade-off given the business need for speed and reliability.
